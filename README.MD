# PySpark & AWS
## Topics 
- Introduction and importance of Big Data.
- Practical explanation and live coding using PySpark.
- Spark applications
- Spark EcoSystem
- Spark architecture
- EcoSystem Hadoop
- Hadoop architecture
- PySpark RDD
- PySpark RDD transformations
- PySpark RDD actions
- PySpark DataFrames
- PySpark DataFrames Transformations
- PySpark DataFrames Actions
- Collaborative filtering in PySpark
- Spark Streaming
- ETL Pipeline
- CDC and on-the-fly replication

## Project

### 1. Spark RDDs

Analytics data:
- Number of students in the file,
- Total marks achieved by Female and Male students,
- Total number of students that have passed and failed (50+ marks are required to pass the course),
- Total number of students enrolled per course,
- Total marks that students have achieved per course,
- Average marks that students have achieved per course,
- Minimum and maximum marks achieved per course,
- Average age of male and female students.


### 2. Spark DFs

- Total number of employees in the company,
- Total number of departments in the company,
- Department names of the company,
- Total number of employees in each department,
- Total number of employees in each state,
- Total number of employees in each state in each department,
- Minimum and maximum salaries in each department and sort salaries in ascending order,
- Names of employees working in NY state under Finance department whose bonuses are greater than the average bonuses of employees in NY state,
- Raise the salaries $500 of all employees whose age is greater than 45,
- Create DF of all those employees whose age is greater than 45 and save them in a file,

### 3. Collaborative filtering

Collaborative filtering is a technique used by recommender systems.

### 4. ETL Pipeline

- EXTRACT data from its original source
- TRANSFORM data by deduplicating it, combining it, and ensuring quality, to then
- LOAD data into the target database